\documentclass[11pt]{article}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumitem}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\R}{\mathbb{R}}
\renewcommand{\P}{{\cal P}}
\renewcommand{\S}{{\cal S}}

\pagestyle{empty}


\begin{document}

\setlength{\parindent}{0pt}
\setlength{\parskip}{9pt}


\section*{Math 351: Homework 10  Due Friday December 7}
\subsection*{Jack Ellert-Beck}

\bigskip

\subsection*{Chopping}

Use Lemma 3.3.4 to complete the proof of the chopping lemma, Lemma 3.2.1

[Use angle difference formulas. Argue that the above argument for sin works
for cos as well. Create a period of $2\pi/k$ with some error that
disappears as $k\to\infty$ (that part might not quite be right)]

\subsection*{0.1 Jensen's}

Exercise 5.1: Prove lemma 5.2.2.

Lemma: If $\rho$ is convex on $I$, and $x_1,x_2\in I$, and equality holds
\[
    \rho(wx_1+(1-w)x_2)\leq w\rho(x_1)+(1-w)\rho(x_2)
\]
for some $0<w<1$, then either $x_1=x_2$ or $\rho$ is linear on $[x_1,x_2]$.

[BY CONTRADICTION? CONFUSING]

Exercise 5.2: Prove lemma 5.2.3.

Lemma: If $\rho$ is a convex function on an interval $I$,
$x_1,\ldots,x_n\in I$,
and $w_1,\ldots,w_n$ are non-negative real numbers with $\sum w_i=1$, then
\[
    \rho\left(\sum w_ix_i\right)\leq\sum w_i\rho(x_i)
\]
with equality holding iff $\rho$ is linear on an interval containing the
$x_i$'s, or all $x_i$'s are the same.

We proceed by induction. The base case is where $n=2$, which is true by
Lemma 5.2.2.

For the inductive step, assume that 
\[
    \rho\left(\sum_{i=0}^n w_ix_i\right)=\sum_{i=0}^n w_i\rho(x_i)
\]
implies that either all $x_i$'s are the same or $\rho$ is linear 
for some $n\geq2$. We will show that
\[
    \rho\left(\sum_{i=0}^{n+1} w_ix_i\right)=\sum_{i=0}^{n+1} w_i\rho(x_i)
\]
implies that either all $x_i$'s are the same or $\rho$ is linear.
We rewrite the latter equation:
\[
\def\arraystretch{1.5}
\begin{array}{rl}
& \rho\left(\sum_{i=0}^{n+1}w_ix_i\right) =
    \rho\left(\left(\sum_{i=0}^nw_ix_i\right)+w_{n+1}x_{n+1}\right) \\
\textrm{by Lemma 5.2.2}&\implies \sum_{i=0}^nw_i\rho(x_i)+w_{n+1}\rho(x_{n+1}) \\
&\implies \sum_{i=0}^{n+1}w_ix_i \\
&\implies \textrm{ and that either $x_i$'s are the same or $\rho$ is linear.}
\end{array}
\]

Exercise 5.3: Prove that convex functions are continuous.

We will show that if a function $\rho:I\to\R$ (where $I=(a,b)$) has the property that, for
$x_1,x_2\in I$ and all $0\leq w\leq1$,
$\rho(wx_1+(1-w)x_2)\leq w\rho(x_1)+(1-w)\rho(x_2)$,
then it is continuous on $(a,b)$, meaning that, at any $c\in I$,
$\forall \varepsilon>0\ \exists\delta$ such that
$|x-a|<\delta\implies|\rho(x)-\rho(c)|<\varepsilon$.

First, we will see that $\rho(x)$ is bounded on $I$.
Let $A=\min(\rho(a),\rho(b))$.
Note that any $c\in[a,b]$ can be written as
$wa+(1-w)b$ when $w=\frac{b-c}{b-a}$. Thus, by convexity,
$\rho(c)\leq w\rho(a)+(1-w)\rho(b)\leq wA+(1-w)=A$.

Pick any $\varepsilon>0$. If
$\varepsilon\geq\max(|\rho(c)-\rho(b)|,|\rho(a)-\rho(c)|)$, then any
choice of $\delta$ satisfies the definition of continuity. So, we now
consider only cases where
$\varepsilon<A-\rho(c)$. Let $c_1=\frac{a-c}{2}$.
If $|\rho(c_1)-\rho(c)|<\varepsilon$, then pick $\delta<|c_1-c|$. If not,
let $c_2=\frac{c_1-c}{c}$. Note that $c<c_2<c_1$.
Keep picking $c_n$ in this way until, for some $N$,
$|\rho(c_N)-\rho(c)|<\varepsilon$. Choosing $0<\delta<c_N$ will make
$|f(c)-f(x)|<\varepsilon$. Thus, $\rho$ is continuous on $I$.

\subsection*{0.2 Euler-Lagrange}

Exercise 4.1: Use Euler-Lagrange to find the extremals for:

a) $\int_1^2y'^2/x^3dx$ with $y(1)=2,y(2)=17$
\[
\def\arraystretch{1.5}
\begin{array}{rl}
    g(x,y,y')=y'^2/x^3 &\textrm{and}\ 
    \frac{\partial g}{\partial y}-\frac{d}{dx}\left(\frac{\partial g}{\partial y'}\right)=0 \\
    &\implies 0-\frac{d}{dx}\left(\frac{2y'}{x^3}\right)=0 \\
    &\implies \frac{2y'}{x^3}=C_0\textrm{ for some constant $C_0$} \\
    &\implies y'=\frac{C_0}{2}x^3 \\
    &\implies y=\int\frac{C_0}{2}x^3dx=C_1x^4+C_2 \\
    \textrm{so }1C_1+C_2=2\textrm{ and }16C_1+C_2=17 &\implies
    C_1=1,\ C_2=1 \\
    &\implies y=x^4+1
\end{array}
\]

b) $\int_0^{\pi/2}y^2-y'^2-2y\sin(x) dx$ with $y(0)=1,y(\pi/2)=1$
\[
\def\arraystretch{1.5}
\begin{array}{rl}
    g(x,y,y')=y^2-y'^2-2y\sin(x) &\textrm{and}\ 
    \frac{\partial g}{\partial y}-\frac{d}{dx}\left(\frac{\partial g}{\partial y'}\right)=0 \\
    &\implies (2y-2\sin(x))-\frac{d}{dx}\left(-2y'\right)=0 \\
    &\implies y''=\sin(x)-y \\
    &\implies y=C_2\sin(x)+C_1\cos(x)-\frac{1}{2}x\cos(x) \\
    &\textrm{ (from Mathematica) } \\
    \textrm{so }0C_2+1C_1-0=1\textrm{ and }1C_2+0C_1-0=1 &\implies
    C_1=1,\ C_2=1 \\
    &\implies y=\sin(x)+\cos(x)-\frac{1}{2}x\cos(x)
\end{array}
\]

c) $\int_0^\pi y'^2+2y\sin(x) dx$ with $y(0)=0,y(\pi)=0$
\[
\def\arraystretch{1.5}
\begin{array}{rl}
    g(x,y,y')=y'^2+2y\sin(x) &\textrm{and}\ 
    \frac{\partial g}{\partial y}-\frac{d}{dx}\left(\frac{\partial g}{\partial y'}\right)=0 \\
    &\implies 2\sin(x)-\frac{d}{dx}\left(2y'\right)=0 \\
    &\implies y''=\sin(x) \\
    &\implies y=-\sin(x)+C_1x+C_2\\
    &\textrm{ (from Mathematica) } \\
    \textrm{so }0C_1+C_2=0\textrm{ and }\pi C_1+C_2=0 &\implies
    C_1=0,\ C_2=0 \\
    &\implies y=-\sin(x)
\end{array}
\]



\end{document}
